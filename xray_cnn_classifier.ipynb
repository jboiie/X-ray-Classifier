{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157ad284",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Cell 2: Configuration\n",
    "IMAGE_SIZE = (150, 150)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "MODEL_PATH = 'models/xray_cnn_model.h5'\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('sample_images', exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Loading and Preprocessing\n",
    "# Data paths (adjust based on your dataset structure)\n",
    "train_dir = 'chest_xray/train'\n",
    "val_dir = 'chest_xray/val'\n",
    "test_dir = 'chest_xray/test'\n",
    "\n",
    "# Data Augmentation and Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Load datasets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {val_generator.samples}\")\n",
    "print(f\"Test samples: {test_generator.samples}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Model Architecture\n",
    "def create_cnn_model():\n",
    "    model = keras.Sequential([\n",
    "        # First Convolutional Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Fourth Convolutional Block\n",
    "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Flatten and Dense Layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile model\n",
    "model = create_cnn_model()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a734de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Training\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2),\n",
    "    keras.callbacks.ModelCheckpoint(MODEL_PATH, save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save training history\n",
    "with open('models/training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275d2646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Evaluation and Visualization\n",
    "# Evaluation\n",
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_generator)\n",
    "f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "\n",
    "print(f\"\\n=== Test Results ===\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n",
    "\n",
    "# Save evaluation metrics\n",
    "metrics = {\n",
    "    'accuracy': float(test_accuracy),\n",
    "    'precision': float(test_precision),\n",
    "    'recall': float(test_recall),\n",
    "    'f1_score': float(f1_score)\n",
    "}\n",
    "\n",
    "with open('models/evaluation_metrics.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57adc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Training History Visualization\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "    ax1.set_title('Model Accuracy Over Time')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
    "    ax2.set_title('Model Loss Over Time')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('models/training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5931ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Sample Predictions\n",
    "def save_sample_predictions(model, test_generator, num_samples=6):\n",
    "    predictions = model.predict(test_generator)\n",
    "    \n",
    "    # Get sample images and their true labels\n",
    "    test_generator.reset()\n",
    "    sample_batch = next(test_generator)\n",
    "    images, true_labels = sample_batch\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        axes[i].imshow(images[i])\n",
    "        \n",
    "        pred_prob = predictions[i][0]\n",
    "        pred_class = \"Pneumonia\" if pred_prob > 0.5 else \"Normal\"\n",
    "        true_class = \"Pneumonia\" if true_labels[i] == 1 else \"Normal\"\n",
    "        \n",
    "        axes[i].set_title(f\"Prediction: {pred_class} ({pred_prob:.3f})\\nActual: {true_class}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('models/sample_predictions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "save_sample_predictions(model, test_generator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56777398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Model Architecture Diagram\n",
    "keras.utils.plot_model(\n",
    "    model, \n",
    "    to_file='models/model_architecture.png', \n",
    "    show_shapes=True, \n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    dpi=300\n",
    ")\n",
    "\n",
    "print(\"✅ Model training completed!\")\n",
    "print(\"✅ All artifacts saved in 'models/' directory\")\n",
    "print(\"✅ Ready for Streamlit deployment!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
